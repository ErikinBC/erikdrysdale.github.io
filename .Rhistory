dat <- tbl_df(data.frame(t.obs=ifelse(is.censored,rc,rw),t.true=rw,censored=is.censored,X))
# Log-likelihood with censoring
# theta <- c(1,1,-0.5);t=dat$t.obs;censor=dat$censored;dat=cbind(1,dat$treatment)
llik.censor <- function(theta,t,censor,dat) {
t1 <- theta[1] # alpha
t2 <- theta[2] # beta_0
t3 <- theta[3] # beta_1
# Find which observations are censored
C.obs <- which(censor)
U.obs <- which(!censor)
# Calculate observations beforehand
fv <- dat %*% rbind(t2,t3)
fv.C <- fv[C.obs]; fv.U <- fv[U.obs]
t.C <- t[C.obs]; t.U <- t[U.obs]
# Calculate
# -1* ( sum( log(t1) + t1*log(fv) + (t1-1)*log(t) ) + sum( -(fv*t)^t1  ) )
-1*( sum( log(t1) + t1*log(fv.U) + (t1-1)*log(t.U) ) + sum( -(fv.U*t.U)^t1  ) + sum( -(fv.C*t.C)^t1  )  )
}
# Optimize
mlik.censor <- optim(par=c(1,0.5,0),fn=llik.censor,t=dat$t.obs,censor=dat$censored,dat=cbind(1,dat$treatment))$par
mlik.wrong <- optim(par=c(1,0.5,0),fn=llik,t=dat$t.obs,dat=cbind(1,dat$treatment))$par
data.frame(Parameters=c('alpha','beta[0]','beta[1]'),
True.Value=round(c(alpha,beta),1),
'ML with censoring'=round(mlik.censor,1),
'ML without censoring'=round(mlik.wrong,1))
n <- 1000
set.seed(1)
X <- data.frame(iota=1,treatment=rbernoulli(n)*1) %>% as.matrix
# Generate censored observations with probability 50%
rw <- rweibull(n,shape=alpha,scale=1 / (X %*% beta))
rc <- runif(n,min=0,max=rw)
is.censored <- rbernoulli(n)
dat <- tbl_df(data.frame(t.obs=ifelse(is.censored,rc,rw),t.true=rw,censored=is.censored,X))
# Log-likelihood with censoring
# theta <- c(1,1,-0.5);t=dat$t.obs;censor=dat$censored;dat=cbind(1,dat$treatment)
llik.censor <- function(theta,t,censor,dat) {
t1 <- theta[1] # alpha
t2 <- theta[2] # beta_0
t3 <- theta[3] # beta_1
# Find which observations are censored
C.obs <- which(censor)
U.obs <- which(!censor)
# Calculate observations beforehand
fv <- dat %*% rbind(t2,t3)
fv.C <- fv[C.obs]; fv.U <- fv[U.obs]
t.C <- t[C.obs]; t.U <- t[U.obs]
# Calculate
# -1* ( sum( log(t1) + t1*log(fv) + (t1-1)*log(t) ) + sum( -(fv*t)^t1  ) )
-1*( sum( log(t1) + t1*log(fv.U) + (t1-1)*log(t.U) ) + sum( -(fv.U*t.U)^t1  ) + sum( -(fv.C*t.C)^t1  )  )
}
# Optimize
mlik.censor <- optim(par=c(1,0.5,0),fn=llik.censor,t=dat$t.obs,censor=dat$censored,dat=cbind(1,dat$treatment))$par
mlik.wrong <- optim(par=c(1,0.5,0),fn=llik,t=dat$t.obs,dat=cbind(1,dat$treatment))$par
data.frame(Parameters=c('alpha','beta[0]','beta[1]'),
True.Value=round(c(alpha,beta),1),
'ML with censoring'=round(mlik.censor,1),
'ML without censoring'=round(mlik.wrong,1))
a <- mlik.censor[1]
b1 <- mlik.censor[2]
b2 <- mlik.censor[3]
theta.treat <- sum(c(1,1)*c(b1,b2))
theta.notreat <- sum(c(1,0)*c(b1,b2))
mu.treat <- (1/theta.treat)*gamma(1+1/a)
mu.notreat <- (1/theta.notreat)*gamma(1+1/a)
xbar <- dat %>% group_by(treatment) %>% summarise(xbar=mean(t.obs))
x.all <- dat %>% group_by(treatment) %>% summarise(xbar=mean(t.true))
# Print
data.frame(Treatment=c('Yes','No'),Inference=c(mu.treat,mu.notreat),
'Sample-mean'=c(rev(xbar$xbar)),'True sample-mean'=c(rev(x.all$xbar)))
n <- 10000
set.seed(1)
X <- data.frame(iota=1,treatment=rbernoulli(n)*1) %>% as.matrix
# Generate censored observations with probability 50%
rw <- rweibull(n,shape=alpha,scale=1 / (X %*% beta))
rc <- runif(n,min=0,max=rw)
is.censored <- rbernoulli(n)
dat <- tbl_df(data.frame(t.obs=ifelse(is.censored,rc,rw),t.true=rw,censored=is.censored,X))
# Log-likelihood with censoring
# theta <- c(1,1,-0.5);t=dat$t.obs;censor=dat$censored;dat=cbind(1,dat$treatment)
llik.censor <- function(theta,t,censor,dat) {
t1 <- theta[1] # alpha
t2 <- theta[2] # beta_0
t3 <- theta[3] # beta_1
# Find which observations are censored
C.obs <- which(censor)
U.obs <- which(!censor)
# Calculate observations beforehand
fv <- dat %*% rbind(t2,t3)
fv.C <- fv[C.obs]; fv.U <- fv[U.obs]
t.C <- t[C.obs]; t.U <- t[U.obs]
# Calculate
# -1* ( sum( log(t1) + t1*log(fv) + (t1-1)*log(t) ) + sum( -(fv*t)^t1  ) )
-1*( sum( log(t1) + t1*log(fv.U) + (t1-1)*log(t.U) ) + sum( -(fv.U*t.U)^t1  ) + sum( -(fv.C*t.C)^t1  )  )
}
# Optimize
mlik.censor <- optim(par=c(1,0.5,0),fn=llik.censor,t=dat$t.obs,censor=dat$censored,dat=cbind(1,dat$treatment))$par
mlik.wrong <- optim(par=c(1,0.5,0),fn=llik,t=dat$t.obs,dat=cbind(1,dat$treatment))$par
data.frame(Parameters=c('alpha','beta[0]','beta[1]'),
True.Value=round(c(alpha,beta),1),
'ML with censoring'=round(mlik.censor,1),
'ML without censoring'=round(mlik.wrong,1))
mlik.censor
a <- mlik.censor[1]
b1 <- mlik.censor[2]
b2 <- mlik.censor[3]
theta.treat <- sum(c(1,1)*c(b1,b2))
theta.notreat <- sum(c(1,0)*c(b1,b2))
mu.treat <- (1/theta.treat)*gamma(1+1/a)
mu.notreat <- (1/theta.notreat)*gamma(1+1/a)
xbar <- dat %>% group_by(treatment) %>% summarise(xbar=mean(t.obs))
x.all <- dat %>% group_by(treatment) %>% summarise(xbar=mean(t.true))
# Print
data.frame(Treatment=c('Yes','No'),Inference=c(mu.treat,mu.notreat),
'Sample-mean'=c(rev(xbar$xbar)),'True sample-mean'=c(rev(x.all$xbar)))
n <- 50
set.seed(1)
X <- data.frame(iota=1,treatment=rbernoulli(n)*1) %>% as.matrix
# Generate censored observations with probability 50%
rw <- rweibull(n,shape=alpha,scale=1 / (X %*% beta))
rc <- runif(n,min=0,max=rw)
is.censored <- rbernoulli(n)
dat <- tbl_df(data.frame(t.obs=ifelse(is.censored,rc,rw),t.true=rw,censored=is.censored,X))
# Log-likelihood with censoring
# theta <- c(1,1,-0.5);t=dat$t.obs;censor=dat$censored;dat=cbind(1,dat$treatment)
llik.censor <- function(theta,t,censor,dat) {
t1 <- theta[1] # alpha
t2 <- theta[2] # beta_0
t3 <- theta[3] # beta_1
# Find which observations are censored
C.obs <- which(censor)
U.obs <- which(!censor)
# Calculate observations beforehand
fv <- dat %*% rbind(t2,t3)
fv.C <- fv[C.obs]; fv.U <- fv[U.obs]
t.C <- t[C.obs]; t.U <- t[U.obs]
# Calculate
# -1* ( sum( log(t1) + t1*log(fv) + (t1-1)*log(t) ) + sum( -(fv*t)^t1  ) )
-1*( sum( log(t1) + t1*log(fv.U) + (t1-1)*log(t.U) ) + sum( -(fv.U*t.U)^t1  ) + sum( -(fv.C*t.C)^t1  )  )
}
# Optimize
mlik.censor <- optim(par=c(1,0.5,0),fn=llik.censor,t=dat$t.obs,censor=dat$censored,dat=cbind(1,dat$treatment))$par
mlik.wrong <- optim(par=c(1,0.5,0),fn=llik,t=dat$t.obs,dat=cbind(1,dat$treatment))$par
data.frame(Parameters=c('alpha','beta[0]','beta[1]'),
True.Value=round(c(alpha,beta),1),
'ML with censoring'=round(mlik.censor,1),
'ML without censoring'=round(mlik.wrong,1))
n <- 200
set.seed(1)
X <- data.frame(iota=1,treatment=rbernoulli(n)*1) %>% as.matrix
# Generate censored observations with probability 50%
rw <- rweibull(n,shape=alpha,scale=1 / (X %*% beta))
rc <- runif(n,min=0,max=rw)
is.censored <- rbernoulli(n)
dat <- tbl_df(data.frame(t.obs=ifelse(is.censored,rc,rw),t.true=rw,censored=is.censored,X))
# Log-likelihood with censoring
# theta <- c(1,1,-0.5);t=dat$t.obs;censor=dat$censored;dat=cbind(1,dat$treatment)
llik.censor <- function(theta,t,censor,dat) {
t1 <- theta[1] # alpha
t2 <- theta[2] # beta_0
t3 <- theta[3] # beta_1
# Find which observations are censored
C.obs <- which(censor)
U.obs <- which(!censor)
# Calculate observations beforehand
fv <- dat %*% rbind(t2,t3)
fv.C <- fv[C.obs]; fv.U <- fv[U.obs]
t.C <- t[C.obs]; t.U <- t[U.obs]
# Calculate
# -1* ( sum( log(t1) + t1*log(fv) + (t1-1)*log(t) ) + sum( -(fv*t)^t1  ) )
-1*( sum( log(t1) + t1*log(fv.U) + (t1-1)*log(t.U) ) + sum( -(fv.U*t.U)^t1  ) + sum( -(fv.C*t.C)^t1  )  )
}
# Optimize
mlik.censor <- optim(par=c(1,0.5,0),fn=llik.censor,t=dat$t.obs,censor=dat$censored,dat=cbind(1,dat$treatment))$par
mlik.wrong <- optim(par=c(1,0.5,0),fn=llik,t=dat$t.obs,dat=cbind(1,dat$treatment))$par
data.frame(Parameters=c('alpha','beta[0]','beta[1]'),
True.Value=round(c(alpha,beta),1),
'ML with censoring'=round(mlik.censor,1),
'ML without censoring'=round(mlik.wrong,1))
n <- 500
set.seed(1)
X <- data.frame(iota=1,treatment=rbernoulli(n)*1) %>% as.matrix
# Generate censored observations with probability 50%
rw <- rweibull(n,shape=alpha,scale=1 / (X %*% beta))
rc <- runif(n,min=0,max=rw)
is.censored <- rbernoulli(n)
dat <- tbl_df(data.frame(t.obs=ifelse(is.censored,rc,rw),t.true=rw,censored=is.censored,X))
# Log-likelihood with censoring
# theta <- c(1,1,-0.5);t=dat$t.obs;censor=dat$censored;dat=cbind(1,dat$treatment)
llik.censor <- function(theta,t,censor,dat) {
t1 <- theta[1] # alpha
t2 <- theta[2] # beta_0
t3 <- theta[3] # beta_1
# Find which observations are censored
C.obs <- which(censor)
U.obs <- which(!censor)
# Calculate observations beforehand
fv <- dat %*% rbind(t2,t3)
fv.C <- fv[C.obs]; fv.U <- fv[U.obs]
t.C <- t[C.obs]; t.U <- t[U.obs]
# Calculate
# -1* ( sum( log(t1) + t1*log(fv) + (t1-1)*log(t) ) + sum( -(fv*t)^t1  ) )
-1*( sum( log(t1) + t1*log(fv.U) + (t1-1)*log(t.U) ) + sum( -(fv.U*t.U)^t1  ) + sum( -(fv.C*t.C)^t1  )  )
}
# Optimize
mlik.censor <- optim(par=c(1,0.5,0),fn=llik.censor,t=dat$t.obs,censor=dat$censored,dat=cbind(1,dat$treatment))$par
mlik.wrong <- optim(par=c(1,0.5,0),fn=llik,t=dat$t.obs,dat=cbind(1,dat$treatment))$par
data.frame(Parameters=c('alpha','beta[0]','beta[1]'),
True.Value=round(c(alpha,beta),1),
'ML with censoring'=round(mlik.censor,1),
'ML without censoring'=round(mlik.wrong,1))
mlik.censor
a <- mlik.censor[1]
b1 <- mlik.censor[2]
b2 <- mlik.censor[3]
theta.treat <- sum(c(1,1)*c(b1,b2))
theta.notreat <- sum(c(1,0)*c(b1,b2))
mu.treat <- (1/theta.treat)*gamma(1+1/a)
mu.notreat <- (1/theta.notreat)*gamma(1+1/a)
xbar <- dat %>% group_by(treatment) %>% summarise(xbar=mean(t.obs))
x.all <- dat %>% group_by(treatment) %>% summarise(xbar=mean(t.true))
# Print
data.frame(Treatment=c('Yes','No'),Inference=c(mu.treat,mu.notreat),
'Sample-mean'=c(rev(xbar$xbar)),'True sample-mean'=c(rev(x.all$xbar)))
data.frame(Treatment=c('Yes','No'),Inference=c(mu.treat,mu.notreat),
'Sample-mean'=c(rev(xbar$xbar)),'True sample-mean'=c(rev(x.all$xbar))) %>%
mutate_if(is.numeric,funs(round(.,1)))
data.frame(n=10^(seq(1,5,1)))
n <- 10^(seq(1,5,1))
rweibull(n=c(5,10),shape=alpha,scale=1/sum(beta))
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
data.frame(n=n,xbar=sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean %>% round(2))
)
data.frame(Observations=n,xbar=sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean %>% round(2))
n <- 10^(seq(1,5,1))
data.frame(Observations=n,xbar=sapply(n,function(nn)
n <- 10^(seq(1,5,1))
data.frame(Observations=n,xbar=sapply(n,function(nn)
rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean %>% round(2)))
n <- c(10,100,1000,10000,100000)
data.frame(Observations=n,xbar=sapply(n,function(nn)
rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean %>% round(2)))
set.seed(1)
n <- c(10,100,1000,10000,100000)
data.frame(Observations=n,xbar=sapply(n,function(nn)
rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean %>% round(2)))
set.seed(1)
n <- c(100,1000,10000,100000)
data.frame(Observations=n,xbar=sapply(n,function(nn)
rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean %>% round(2)))
set.seed(1)
n <- c(100,1000,10000,100000)
data.frame(Observations=n,xbar=sapply(n,function(nn)
rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean %>% round(2)))
n <- seq(1000,10000,1000)
data.frame(Observations=n,xbar=sapply(n,function(nn)
rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean %>% round(2)))
set.seed(1)
n <- seq(1000,100000,10000)
data.frame(Observations=n,xbar=sapply(n,function(nn)
rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean %>% round(2)))
set.seed(1)
n <- seq(10,100,500,1000,10000)
data.frame(Observations=n,xbar=sapply(n,function(nn)
rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean %>% round(2)))
set.seed(1)
n <- c(10,100,500,1000,10000)
data.frame(Observations=n,xbar=sapply(n,function(nn)
rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean %>% round(2)))
set.seed(1)
n <- c(10,50,100,500,1000,10000)
data.frame(Observations=n,xbar=sapply(n,function(nn)
rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean %>% round(2)))
alpha
beta
1/sum(beta)
gamma(1+1/alpha)
set.seed(1)
# n <- c(10,50,100,500,1000,10000)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
set.seed(1)
# n <- c(10,50,100,500,1000,10000)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
n <- 10^(seq(1,5,1))
sapply(n,function(nn) rweibull(nn,shape=alpha,scale=1/sum(beta)) %>% mean)
head(dat)
sum(dat$censored)
n
n <- 500
set.seed(1)
X <- data.frame(iota=1,treatment=rbernoulli(n)*1) %>% as.matrix
# Generate censored observations with probability 50%
rw <- rweibull(n,shape=alpha,scale=1 / (X %*% beta))
rc <- runif(n,min=0,max=rw)
is.censored <- rbernoulli(n)
dat <- tbl_df(data.frame(t.obs=ifelse(is.censored,rc,rw),t.true=rw,censored=is.censored,X))
# Log-likelihood with censoring
# theta <- c(1,1,-0.5);t=dat$t.obs;censor=dat$censored;dat=cbind(1,dat$treatment)
llik.censor <- function(theta,t,censor,dat) {
t1 <- theta[1] # alpha
t2 <- theta[2] # beta_0
t3 <- theta[3] # beta_1
# Find which observations are censored
C.obs <- which(censor)
U.obs <- which(!censor)
# Calculate observations beforehand
fv <- dat %*% rbind(t2,t3)
fv.C <- fv[C.obs]; fv.U <- fv[U.obs]
t.C <- t[C.obs]; t.U <- t[U.obs]
# Calculate
# -1* ( sum( log(t1) + t1*log(fv) + (t1-1)*log(t) ) + sum( -(fv*t)^t1  ) )
-1*( sum( log(t1) + t1*log(fv.U) + (t1-1)*log(t.U) ) + sum( -(fv.U*t.U)^t1  ) + sum( -(fv.C*t.C)^t1  )  )
}
# Optimize
mlik.censor <- optim(par=c(1,0.5,0),fn=llik.censor,t=dat$t.obs,censor=dat$censored,dat=cbind(1,dat$treatment))$par
mlik.wrong <- optim(par=c(1,0.5,0),fn=llik,t=dat$t.obs,dat=cbind(1,dat$treatment))$par
data.frame(Parameters=c('alpha','beta[0]','beta[1]'),
True.Value=round(c(alpha,beta),1),
'ML with censoring'=round(mlik.censor,1),
'ML without censoring'=round(mlik.wrong,1))
n
1+(1.37/(r-1.92))*sqrt(n/r)
r <- sum(dat$censored)
1+(1.37/(r-1.92))*sqrt(n/r)
(1.37/(r-1.92))
r-1.92
1.37/(r-1.92)
sqrt(n/r)
(1.37/(r-1.92))*sqrt(n/r)
n <- 100
set.seed(1)
X <- data.frame(iota=1,treatment=rbernoulli(n)*1) %>% as.matrix
# Generate censored observations with probability 50%
rw <- rweibull(n,shape=alpha,scale=1 / (X %*% beta))
rc <- runif(n,min=0,max=rw)
is.censored <- rbernoulli(n)
dat <- tbl_df(data.frame(t.obs=ifelse(is.censored,rc,rw),t.true=rw,censored=is.censored,X))
# Log-likelihood with censoring
# theta <- c(1,1,-0.5);t=dat$t.obs;censor=dat$censored;dat=cbind(1,dat$treatment)
llik.censor <- function(theta,t,censor,dat) {
t1 <- theta[1] # alpha
t2 <- theta[2] # beta_0
t3 <- theta[3] # beta_1
# Find which observations are censored
C.obs <- which(censor)
U.obs <- which(!censor)
# Calculate observations beforehand
fv <- dat %*% rbind(t2,t3)
fv.C <- fv[C.obs]; fv.U <- fv[U.obs]
t.C <- t[C.obs]; t.U <- t[U.obs]
# Calculate
-1*( sum( log(t1) + t1*log(fv.U) + (t1-1)*log(t.U) ) + sum( -(fv.U*t.U)^t1  ) + sum( -(fv.C*t.C)^t1  )  )
}
# Optimize
mlik.censor <- optim(par=c(1,0.5,0),fn=llik.censor,t=dat$t.obs,censor=dat$censored,dat=cbind(1,dat$treatment))$par
mlik.wrong <- optim(par=c(1,0.5,0),fn=llik,t=dat$t.obs,dat=cbind(1,dat$treatment))$par
data.frame(Parameters=c('alpha','beta[0]','beta[1]'),
True.Value=round(c(alpha,beta),1),
'ML with censoring'=round(mlik.censor,1),
'ML without censoring'=round(mlik.wrong,1))
a <- mlik.censor[1]
b1 <- mlik.censor[2]
b2 <- mlik.censor[3]
theta.treat <- sum(c(1,1)*c(b1,b2))
theta.notreat <- sum(c(1,0)*c(b1,b2))
mu.treat <- (1/theta.treat)*gamma(1+1/a)
mu.notreat <- (1/theta.notreat)*gamma(1+1/a)
xbar <- dat %>% group_by(treatment) %>% summarise(xbar=mean(t.obs))
x.all <- dat %>% group_by(treatment) %>% summarise(xbar=mean(t.true))
# Print
data.frame(Treatment=c('Yes','No'),Inference=c(mu.treat,mu.notreat),
'Sample-mean'=c(rev(xbar$xbar)),'True sample-mean'=c(rev(x.all$xbar))) %>%
mutate_if(is.numeric,funs(round(.,1)))
data.frame(Treatment=c('Yes','No'),Inference=c(mu.treat,mu.notreat),
'Sample-mean'=c(rev(xbar$xbar)),'True sample-mean'=c(rev(x.all$xbar))) %>%
mutate_if(is.numeric,funs(round(.,2)))
data.frame(Treatment=c('Yes','No'),Inference=c(mu.treat,mu.notreat),
'Sample-mean'=c(rev(xbar$xbar)),'True sample-mean'=c(rev(x.all$xbar))) %>%
mutate_if(is.numeric,funs(round(.,1)))
rmd2
#' This R script will process all R mardown files (those with in_ext file extention,
#' .rmd by default) in the current working directory. Files with a status of
#' 'processed' will be converted to markdown (with out_ext file extention, '.markdown'
#' by default). It will change the published parameter to 'true' and change the
#' status parameter to 'publish'.
#'
#' @param path_site path to the local root storing the site files
#' @param dir_rmd directory containing R Markdown files (inputs)
#' @param dir_md directory containing markdown files (outputs)
#' @param url_images where to store/get images created from plots directory +"/" (relative to path_site)
#' @param out_ext the file extention to use for processed files.
#' @param in_ext the file extention of input files to process.
#' @param recursive should rmd files in subdirectories be processed.
#' @return nothing.
#' @author Jason Bryer <jason@bryer.org> edited by Andy South
# setwd("C:/Users/erikinwest/Documents/bioeconometrician/github/erikdrysdale.github.io/")
# path_site = getwd();dir_rmd = "_rmd";dir_md = "_posts"
# url_images = "figures/";out_ext='.md';in_ext='.rmd';recursive=FALSE
rm(list=ls())
rmd2md <- function( path_site = getwd(),
dir_rmd = "_rmd",
dir_md = "_posts",
#dir_images = "figures",
url_images = "figures/",
out_ext='.md',
in_ext='.rmd',
recursive=FALSE) {
require(knitr, quietly=TRUE, warn.conflicts=FALSE)
#andy change to avoid path problems when running without sh on windows
files <- list.files(path=file.path(path_site,dir_rmd), pattern=in_ext, ignore.case=TRUE, recursive=recursive)
for(f in files) {
message(paste("Processing ", f, sep=''),encoding = "UTF-8")
content <- readLines(file.path(path_site,dir_rmd,f))
# If any html calls, replace the src=figures/... with src=/figures/...
src.idx <- grep('src=',content,value=F)
if (length(src.idx)>0) {
content[src.idx] <- gsub('src=\"figures','src=\"/figures',content[src.idx])
} else {}
frontMatter <- which(substr(content, 1, 3) == '---')
if(length(frontMatter) >= 2 & 1 %in% frontMatter) {
statusLine <- which(substr(content, 1, 7) == 'status:')
publishedLine <- which(substr(content, 1, 10) == 'published:')
if(statusLine > frontMatter[1] & statusLine < frontMatter[2]) {
status <- unlist(strsplit(content[statusLine], ':'))[2]
status <- sub('[[:space:]]+$', '', status)
status <- sub('^[[:space:]]+', '', status)
if(tolower(status) == 'process') {
#This is a bit of a hack but if a line has zero length (i.e. a
#black line), it will be removed in the resulting markdown file.
#This will ensure that all line returns are retained.
content[nchar(content) == 0] <- ' '
message(paste('Processing ', f, sep=''))
content[statusLine] <- 'status: publish'
content[publishedLine] <- 'published: true'
#andy change to path
outFile <- file.path(path_site, dir_md, paste0(substr(f, 1, (nchar(f)-(nchar(in_ext)))), out_ext))
#render_markdown(strict=TRUE)
#render_markdown(strict=FALSE) #code didn't render properly on blog
#andy change to render for jekyll
render_jekyll(highlight = "pygments")
#render_jekyll(highlight = "prettify") #for javascript
opts_knit$set(out.format='markdown')
# andy BEWARE don't set base.dir!! it caused me problems
# "base.dir is never used when composing the URL of the figures; it is
# only used to save the figures to a different directory.
# The URL of an image is always base.url + fig.path"
# https://groups.google.com/forum/#!topic/knitr/18aXpOmsumQ
# Get data directory
opts_knit$set(root.dir = dir_rmd)
opts_knit$set(base.url = "/")
# opts_knit$set(fig.width = 10)
opts_chunk$set(fig.path = url_images)
# opts_chunk$set(fig.width = 10)
#andy I could try to make figures bigger
#but that might make not work so well on mobile
opts_chunk$set(fig.width  = 8.5,
fig.height = 7.5,
dpi=300)
try(knit(text=content, output=outFile,encoding = "UTF-8"), silent=FALSE)
} else {
warning(paste("Not processing ", f, ", status is '", status,
"'. Set status to 'process' to convert.", sep=''))
}
} else {
warning("Status not found in front matter.")
}
} else {
warning("No front matter found. Will not process this file.")
}
}
invisible()
}
setwd("C:/Users/erikinwest/Documents/bioeconometrician/github/erikdrysdale.github.io/")
rmd2md()
# c1 <- 'black'
# g1 <- ggplot(gather(iris,var,val,-Species) %>% tbl_df,aes(x=val,y=..density..)) +
#   geom_density(aes(fill=Species),color=c1) + facet_wrap(~var)
#
# # Save data in a list
# rmd.list <- list(g1=g1,c1=c1)
# save(rmd.list,file='C:/Users/erikinwest/Documents/bioeconometrician/github/erikdrysdale.github.io/_rmd/rmd_data_test.RData')
# t1 <- readLines( "C:/Users/erikinwest/Documents/bioeconometrician/github/erikdrysdale.github.io/_posts/2016-12-28-batch_effects.md")
# t2 <- readLines( "C:/Users/erikinwest/Documents/bioeconometrician/github/erikdrysdale.github.io/_posts/2016-12-28-old_batch_effects.md")
#
# t1[which(!t1==t2)]
# t2[which(!t1==t2)]
