{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boosting for survival datasets\n",
    "\n",
    "\n",
    "Gradient boosting has revealed itself to be one of the most powerful modern machine learning algorithms as evidenced by its ubiquity in the leader boards of Kaggle competitions. Boosting is a type of **ensemble learning**, a machine learning paradigm in which the final prediction is determined by a combination of models fit to the data. Two of the most popular ensemble algorithms are Random Forests and Gradient Boosting. The former fits many CARTs to the data and then uses a fair-voting system during the inference stage. In contrast gradient boosting iteratively fits CARTs to the training data, where a given CART uses the cumulative residuals from all previous CARTs as its classification/regression task. Whereas Random Forests are very good at providing low variance estimates, boosting techniques specialize in fitting non-linear dependencies in the data. \n",
    "\n",
    "However naive implementations of tree methods can be computationally burdensome when many trees are fit and when there are many variables to consider splits on (due to the greedy nature of the CART algorithm.) The `xgboost` package has been specifically developed to computationally scale well as well as provide built-in regularization techniques to prevent overfitting. This post will show how `xgboost` can be fit to right-censored survival data with a Python implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CALL IN THE NECESSARY LIBRARIES --- #\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "# Some custom utilities for data processing\n",
    "import utils_boosting as uu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst</th>\n",
       "      <th>time</th>\n",
       "      <th>status</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>ph.ecog</th>\n",
       "      <th>ph.karno</th>\n",
       "      <th>pat.karno</th>\n",
       "      <th>meal.cal</th>\n",
       "      <th>wt.loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>306</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>455</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>210</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>883</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst  time  status  age  sex  ph.ecog  ph.karno  pat.karno  meal.cal  \\\n",
       "0   3.0   306       2   74    1      1.0      90.0      100.0    1175.0   \n",
       "1   3.0   455       2   68    1      0.0      90.0       90.0    1225.0   \n",
       "2   3.0  1010       1   56    1      0.0      90.0       90.0       NaN   \n",
       "3   5.0   210       2   57    1      1.0      90.0       60.0    1150.0   \n",
       "4   1.0   883       2   60    1      0.0     100.0       90.0       NaN   \n",
       "\n",
       "   wt.loss  \n",
       "0      NaN  \n",
       "1     15.0  \n",
       "2     15.0  \n",
       "3     11.0  \n",
       "4      0.0  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the lung dataset\n",
    "from lifelines.datasets import load_lung\n",
    "lung_dat = load_lung()\n",
    "lung_dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "Fill in any missing values using the median.\n",
    "\n",
    "Create dummies for the different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mill missing with median\n",
    "lung_dat = lung_dat.fillna(lung_dat.median())\n",
    "# Extract the time and status then drop\n",
    "y = lung_dat['time']\n",
    "# event indicator (1==censored, 2==dead)\n",
    "d = lung_dat['status']\n",
    "# Drop\n",
    "lung_dat.drop(columns=['inst','time','status'],inplace=True)\n",
    "\n",
    "# Encode sex as 0/1\n",
    "dict_sex = {1: 'male', 2:'female'}\n",
    "lung_dat.replace({'sex': dict_sex},inplace=True)\n",
    "dummies_sex = pd.get_dummies(lung_dat.sex,drop_first=True)\n",
    "# Create dummy variables for ph.ecog (we'll keep original integer form too)\n",
    "dict_phecog = {0: 'ph0', 1: 'ph1', 2: 'ph23', 3:'ph23'}\n",
    "lung_dat.replace({'ph.ecog': dict_phecog}, inplace=True)\n",
    "dummies_phecog = pd.get_dummies(lung_dat['ph.ecog'],drop_first=True)\n",
    "# Drop the originals and concatenate\n",
    "lung_dat = pd.concat([lung_dat.drop(columns=['sex','ph.ecog']), pd.concat([dummies_sex, dummies_phecog],axis=1)],axis=1)\n",
    "# Re-check output\n",
    "lung_dat.head()\n",
    "\n",
    "# Convert to numeric versions\n",
    "X = lung_dat.as_matrix()\n",
    "y = np.array(y)\n",
    "d = np.where(np.array(d)==2,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study: xgboost vs ElasticNet\n",
    "\n",
    "To see which model performs better, we'll look at the out-of-sample concordance scores (the *de rigueur* evaluation metric for survival data) for the `ElasticNet` and `xgboost` models. Using an 80/20 training/test split, both models will perform hyperparameter optimizing using 5-fold CV on the training set. This experiment will be repeated 100 times to generate a null distribution of effects and then the two distributions can be compared.\n",
    "\n",
    "Note that stratified CV is used to ensure that our folds have *roughly* an equal number of events. Since an unweighted average scores of concordance scores is being compared, this will ensure that the comparisons are fair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7543859649122807\n",
      "0.543859649122807\n",
      "0.6929824561403509\n",
      "0.543859649122807\n",
      "0.7543859649122807\n",
      "0.543859649122807\n",
      "0.6929824561403509\n",
      "0.543859649122807\n",
      "0.7105263157894737\n",
      "0.543859649122807\n",
      "0.7368421052631579\n",
      "0.543859649122807\n"
     ]
    }
   ],
   "source": [
    "# Import out neccesary modules and set up parameter dictionaries\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "# Define a dictionary of hyperparameters for xgboost\n",
    "\n",
    "# Number of simulations to run\n",
    "nsim = 3\n",
    "\n",
    "lst_score = [] # List to store accuracies in\n",
    "\n",
    "stratfolds = RepeatedKFold(n_splits=2, n_repeats = nsim, random_state=1) #\n",
    "\n",
    "for train_idx, test_index in stratfolds.split(X):\n",
    "    print(np.mean(d[train_idx]))\n",
    "    print(np.mean(d[test_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset, X, y, d for the train/test indices\n",
    "X_train, X_test = X[train_idx,:], X[test_idx,:]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "d_train, d_test = d[train_idx], d[test_idx]\n",
    "# by giving y negative values, this indicates it is \"censored\" for xgboost\n",
    "time_train, time_test = np.where(d_train == 0, -y_train, y_train), np.where(d_test == 0, -y_test, y_test)\n",
    "# Convert training/test data to DMatrices for xgboost\n",
    "dtrain = xgb.DMatrix(X_train, time_train)\n",
    "dtest = xgb.DMatrix(X_test, time_test)\n",
    "\n",
    "# # Fit Elastic net\n",
    "# temp_elnet_cv = ElasticNetCV(l1_ratio=np.linspace(0.01,1), n_alphas=10, cv=5,\n",
    "#                         fit_intercept=True,normalize=True,random_state=1).fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the results\n",
    "\n",
    "As the results below show, whether we use the parameter t-test or non-parametric Wilcoxon (rank-based) test, the `xgboost` model ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27631578947368424"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate the concordance score\n",
    "\n",
    "#preds=np.array([4,3,2,1,2]);z=np.array([1,-2,3,4,5])\n",
    "def conc(preds,z):\n",
    "    preds = np.array(preds)\n",
    "    z = np.array(preds)\n",
    "    # Get the event idx\n",
    "    idx_event = np.where(z > 0)[0]\n",
    "    ee, cc = 0, 0\n",
    "    for ii in idx_event:\n",
    "        idx_rskset = np.where(z[ii] < np.abs(z))[0]\n",
    "        idx_scores = preds[ii] < preds[idx_rskset]\n",
    "        cc += np.sum( idx_scores )\n",
    "        ee += len(idx_scores)\n",
    "    # Return concordance\n",
    "    tmp_conc = cc/ee\n",
    "    return 'concordance', tmp_conc\n",
    "\n",
    "# Fit using the simple CoxPH model\n",
    "np.mean(time_train <0)\n",
    "\n",
    "\n",
    "# Use CV on the training set to do hyperparameter configuration\n",
    "# params={'max_depth': 1,\n",
    "#         'min_child_weight': 1,\n",
    "#         'eta': 0.3,\n",
    "#         'subsample': 1,\n",
    "#         'colsample_bytree': 1,\n",
    "#         'objective': 'survival:cox'}\n",
    "\n",
    "# temp_xgb = xgb.train(params,dtrain,num_boost_round = 2)\n",
    "# preds = temp_xgb.predict(dtest)\n",
    "\n",
    "# conc(preds,time_test)\n",
    "# temp_xgb_cv = xgb.cv(params,dtrain,num_boost_round=20,maximize=True,feval=conc,\n",
    "#                     seed=42,nfold=2,early_stopping_rounds=10)\n",
    "# temp_xgb_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SUPPORT FUNCTIONS --- #\n",
    "n=100\n",
    "beta=np.array([1,2])\n",
    "cens=0.25\n",
    "\n",
    "#def dgp_surv(n,beta):\n",
    "# Error checking\n",
    "if len(beta.shape)==1:\n",
    "    p = beta.shape[0]\n",
    "elif (len(beta.shape)==2) & (beta.shape[1]==1):\n",
    "    p = beta.shape[0]\n",
    "else:\n",
    "    raise ValueError(\"Error! beta is not a (column) vector\")\n",
    "# Create the X values\n",
    "np.random.seed(1)\n",
    "X = np.random.randn(n,p)\n",
    "Xbeta = np.dot(X,beta)\n",
    "# Hazards\n",
    "haz = np.exp(Xbeta)\n",
    "# Generate time bazed on hazard\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
